---
title: "MFP GA analysis"
author: "Remco Benthem de Grave"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
```

```{r lib}
library(tidyverse)
library(magrittr)
library(jsonlite)
library(tcltk)
library(pastecs)
library(here)
```

```{r}
#read the GA JSON files 
  GAFiles <- list.files(here("GA","data","raw"))

  #read in all the GA data files and concatenate them in one data frame
  GAData <- map_df(GAFiles, 
                    \(file) 
                    stream_in(file(
                      here("GA","data","raw",file)
                    ))
                  )

# 
# # dirName <- "/Users/b8058356/Library/CloudStorage/OneDrive-NewcastleUniversity/PhD Personaled Food Recommendation/Study 5/GA/data"
# # if(!exists("dirName")){
# #   dirName <- tk_choose.dir(default = "", caption = "Select directory of GA files")
# # }
# dirName <- here("GA","data")
# 
# if("GAData.json" %in% list.files(here("GA","data"))){
#   GAData <- read_json(path = here("GA","data","GAData.json")) %>% as.tibble()
# } else {
#   GAFiles <- list.files(here("GA","data","raw"))
# 
#   #read in all the GA data files and concatenate them in one data frame
#   GAData <- map_df(GAFiles, 
#                     \(file) 
#                     stream_in(file(
#                       file.path(dirName,file)
#                     ))
#                   )
#   write_json(GAData, here("GA","data","GAData.json"))
# }
```

```{r}
#tidy data
#convert time values to POSIXct
GAData %<>% mutate(event_timestamp = 
                         (as.numeric(event_timestamp) / 1000000) %>% # convert microseconds to seconds
                         as.POSIXct(., origin = "1970-01-01", tz = "Europe/London")) #tz UTC-1 because of erroneous conversion in app
                   # %>% 
                         # format(., "%Y-%m-%d %H:%M:%S")) # format the datetime object

GAData %<>% mutate(user_first_touch_timestamp = 
                         (as.numeric(user_first_touch_timestamp) / 1000000) %>% # convert microseconds to seconds
                         as.POSIXct(., origin = "1970-01-01", tz = "Europe/London")) #tz UTC-1 because of erroneous conversion in app
# %>% 
                         # format(., "%Y-%m-%d %H:%M:%S")) # format the datetime object

#keep only columns of interest
GAData %<>% select(event_timestamp:event_bundle_sequence_id,user_properties:user_first_touch_timestamp, device, user_id)
```

```{r}
#narrow it down to user in events, and those not by the admin
GAData %<>% filter(!is.na(user_id) ) %>% filter(user_id != "6429db483071e41bedb00892" & user_id != "63ff3abb7a74defef8cf5afe" & user_id != "64418ee0379c7d06f5592402" & user_id != "645a19399a8aa035fb824e88")
#these are either the admin or unused accounts

GADataPart <- GAData

```

Events are uniquely identified by the event_bundle_sequence_id.

Some event_bundle_sequence_id's cover more than one event. This causes issues. We will define a number for each individual event within an event_bundle_sequence_id.

```{r}
GADataPart %<>% group_by(event_bundle_sequence_id) %>% mutate(event_nr = row_number()) %>% ungroup() %>% relocate(event_nr, .after = event_bundle_sequence_id)
```



```{r unnest event params}
## some columns are nested dataframes, for clarity we unnest them and remove unwanted columns

###first the event parameters
GADataPart %<>% unnest(event_params)
# nestedDFs <- GAData$event_params %>% map_df(\(df) df) #difficult alternative to unnesting

#the data has been unnested in the form of key-value pairs. Let's unnest that as well
GADataPart %<>% unnest(value)
#the two created columns are string_value and int_value. However, no key seems to be connected with both a integer and a string. Let's check if this is the case, so we can do some data reduction
eval(is.na(GADataPart$string_value) & is.na(GADataPart$int_value)) %>% sum()
eval(!is.na(GADataPart$string_value) & !is.na(GADataPart$int_value)) %>% sum()
#yes, there are no rows that have both a string and an integer value. We can combine these two columns into one
GADataPart %<>% 
  mutate(
    value = ifelse(is.na(int_value),string_value,int_value),
    .keep = "unused",
    .before = string_value
  ) 

#the data has been unnested in the form of key-value pairs (long data) that has created extra rows. 

#let's see which keys (attributes) are of interest to analyse further. By filtering on these keys, we can reduce the data to a more manageable size
unique_events <- GADataPart %>% distinct(key, value)
#looking at the created data, we see that there are still too many unique events to get an overview. Let's look at the unique events after removing some of the keys that have too many events to allow us to get an overview of the rest
#engagement_time_msec is interesting, but it has many values so it's hard to explore other variables; let's look at it again without engagement_time_msec
unique_events %<>% filter(key != "engagement_time_msec")
unique_events %<>% filter(key != "ga_session_id")
#now we can deduct interesting keys:  page_location, event_category, engagement_time_msec, event_label, ga_session_id, ga_session_number?

GADataPart %<>% filter(key %in% c("page_location", "event_category", "engagement_time_msec", "event_label", "ga_session_id", "ga_session_number"))

#now let's give these keys their own column
GADataPart %<>% pivot_wider(names_from = key, values_from = value)
GADataPart %<>% relocate(device, .after = last_col())


```

```{r}
#this investigation showed that we can ignore user_properties for now. Let's remove it
GADataPart %<>% select(!(c(user_properties)))
# #unpack and explore user_properties
# unique_properties <- 
#   GADataPart %>% 
#   select(user_properties) %>% 
#   unnest(user_properties) %>%
#   distinct() %>%
#   arrange(key)
# #this is the user id and event time stamp; let's keep the user_id
# 
# GADataPart %<>% unnest(user_properties)
# GADataPart %<>% unnest(value)
# GADataPart %<>% select(!(c(key, set_timestamp_micros, user_first_touch_timestamp)))
# GADataPart %<>% rename(user_id = string_value)

```

```{r}

#filter out sessions before the briefing (those were me) --> need to check how time is recorded and converted with regard to time zone (mistakes) --> check their sessions in stats to determine

# 644562dce03a186463df54fd before 24-04 11AM UTC+1  
GADataPart %<>% filter(!(user_id == "644562dce03a186463df54fd" & event_timestamp < as.POSIXlt("2023-04-24 11:00", tz="Europe/London")))

#  64478f1f9a8aa035fb823f6c before 25-04 10:30 UTC+1 
GADataPart %<>% filter(!(user_id == "64478f1f9a8aa035fb823f6c" & event_timestamp < as.POSIXlt("2023-04-25 10:30", tz="Europe/London")))

# 6447a6049a8aa035fb823fb8 before 25-04 11:30 UTC+1  
GADataPart %<>% filter(!(user_id == "6447a6049a8aa035fb823fb8" & event_timestamp < as.POSIXlt("2023-04-25 11:40", tz="Europe/London")))

# 6447d364ead1f8e46567534e before 25-04 15:00 UTC+1 
GADataPart %<>% filter(!(user_id == "6447d364ead1f8e46567534e" & event_timestamp < as.POSIXlt("2023-04-25 15:00", tz="Europe/London")))

# 6448f48d9a8aa035fb82410b before 26-04 10:30 UTC+1 
GADataPart %<>% filter(!(user_id == "6448f48d9a8aa035fb82410b" & event_timestamp < as.POSIXlt("2023-04-26 10:30", tz="Europe/London")))

# 64481e059a8aa035fb82407b before 26-04 12:00 UTC+1  
GADataPart %<>% filter(!(user_id == "64481e059a8aa035fb82407b" & event_timestamp < as.POSIXlt("2023-04-26 13:30", tz="Europe/London"))) #looks like colin had GA blocked

# 644963f29a8aa035fb8241af before 26-04 18:30 UTC+1 
GADataPart %<>% filter(!(user_id == "644963f29a8aa035fb8241af" & event_timestamp < as.POSIXlt("2023-04-26 18:30", tz="Europe/London"))) 

# 644a92769a8aa035fb824217 before 27-04 16:00 UTC+1  
GADataPart %<>% filter(!(user_id == "644a92769a8aa035fb824217" & event_timestamp < as.POSIXlt("2023-04-27 16:00", tz="Europe/London"))) #no data for David?

# 644f9adf9a8aa035fb8242df before 01-05 15:00 UTC+1 
GADataPart %<>% filter(!(user_id == "644f9adf9a8aa035fb8242df" & event_timestamp < as.POSIXlt("2023-05-01 15:00", tz="Europe/London"))) 

# 644fad889a8aa035fb824333 before 01-05 17:30 UTC+1 
GADataPart %<>% filter(!(user_id == "644fad889a8aa035fb824333" & event_timestamp < as.POSIXlt("2023-05-01 17:30", tz="Europe/London"))) 

# 644ffe5e9a8aa035fb824387 before 01-05 17:30 UTC+1 
GADataPart %<>% filter(!(user_id == "644ffe5e9a8aa035fb824387" & event_timestamp < as.POSIXlt("2023-05-01 17:30", tz="Europe/London"))) #no data for Will...

# 6450ca419a8aa035fb8243fd before 02-05 12:00 UTC+1  
GADataPart %<>% filter(!(user_id == "6450ca419a8aa035fb8243fd" & event_timestamp < as.POSIXlt("2023-05-02 12:00", tz="Europe/London"))) 

# 64534db1ac23d986b3199a4f before 09-05 12:30 UTC+1 
GADataPart %<>% filter(!(user_id == "64534db1ac23d986b3199a4f" & event_timestamp < as.POSIXlt("2023-05-09 12:30", tz="Europe/London"))) 

# 645a195b9a8aa035fb824e93 before 09-05 12:30 UTC+1 
GADataPart %<>% filter(!(user_id == "645a195b9a8aa035fb824e93" & event_timestamp < as.POSIXlt("2023-05-09 12:30", tz="Europe/London"))) 

# 64510e5d9a8aa035fb82453c before 02-05 14:09 UTC+1 
GADataPart %<>% filter(!(user_id == "64510e5d9a8aa035fb82453c" & event_timestamp < as.POSIXlt("2023-05-02 14:09", tz="Europe/London"))) 


# 6450ef1a9a8aa035fb824491 before 02-05 15:09 UTC+1 
GADataPart %<>% filter(!(user_id == "6450ef1a9a8aa035fb824491" & event_timestamp < as.POSIXlt("2023-05-02 14:09", tz="Europe/London"))) 

# 645220979a8aa035fb824614 before 03-05 10:30 UTC+1 
GADataPart %<>% filter(!(user_id == "645220979a8aa035fb824614" & event_timestamp < as.POSIXlt("2023-05-03 10:30", tz="Europe/London"))) 

# 645228229a8aa035fb82463b before 03-05 10:20 UTC+1 
GADataPart %<>% filter(!(user_id == "645228229a8aa035fb82463b" & event_timestamp < as.POSIXlt("2023-05-03 10:20", tz="Europe/London"))) 

# 645261c49a8aa035fb8246e5 before 03-05 17:30 UTC+1 
GADataPart %<>% filter(!(user_id == "645261c49a8aa035fb8246e5" & event_timestamp < as.POSIXlt("2023-05-03 17:30", tz="Europe/London"))) 

# 645293ac9a8aa035fb824763 before 03-05 17:30 UTC+1 
GADataPart %<>% filter(!(user_id == "645293ac9a8aa035fb824763" & event_timestamp < as.POSIXlt("2023-05-03 17:30", tz="Europe/London"))) 

# 64534f15ac23d986b3199a5a before 04-05 09:00 UTC+1 
GADataPart %<>% filter(!(user_id == "64534f15ac23d986b3199a5a" & event_timestamp < as.POSIXlt("2023-05-04 09:00", tz="Europe/London"))) 

# 64528d129a8aa035fb824756 before 04-05 09:00 UTC+1 
GADataPart %<>% filter(!(user_id == "64528d129a8aa035fb824756" & event_timestamp < as.POSIXlt("2023-05-04 09:00", tz="Europe/London"))) 

# 6454ba719a8aa035fb824931 before 05-05 09:00 UTC+1 
GADataPart %<>% filter(!(user_id == "6454ba719a8aa035fb824931" & event_timestamp < as.POSIXlt("2023-05-05 09:00", tz="Europe/London"))) 

GADataPart %<>% filter(!(user_id == "6453ac32ac23d986b3199a67" & event_timestamp < as.POSIXlt("2023-05-05 09:00", tz="Europe/London"))) 

# 645a16059a8aa035fb824dc2 before 09-05 12:00 UTC+1 
GADataPart %<>% filter(!(user_id == "645a16059a8aa035fb824dc2" & event_timestamp < as.POSIXlt("2023-05-09 12:00", tz="Europe/London"))) 

# 645a43709a8aa035fb824f0a before 09-05 22:00 UTC+1 
GADataPart %<>% filter(!(user_id == "645a43709a8aa035fb824f0a" & event_timestamp < as.POSIXlt("2023-05-09 22:00", tz="Europe/London"))) 


known <- c("644562dce03a186463df54fd", "64478f1f9a8aa035fb823f6c", "6447a6049a8aa035fb823fb8", "6447d364ead1f8e46567534e", "6448f48d9a8aa035fb82410b", "64481e059a8aa035fb82407b",
  "644963f29a8aa035fb8241af", "644a92769a8aa035fb824217", "644f9adf9a8aa035fb8242df",
  "644fad889a8aa035fb824333", "644ffe5e9a8aa035fb824387", "6450ca419a8aa035fb8243fd",
  "64534db1ac23d986b3199a4f", "645a195b9a8aa035fb824e93", "64510e5d9a8aa035fb82453c",
  "645220979a8aa035fb824614", "645228229a8aa035fb82463b", "645261c49a8aa035fb8246e5",
  "645293ac9a8aa035fb824763", "6454ba719a8aa035fb824931", "6450ef1a9a8aa035fb824491",
  "6450ef1a9a8aa035fb824491", "64528d129a8aa035fb824756", "64534f15ac23d986b3199a5a",
  "6453ac32ac23d986b3199a67", "645a16059a8aa035fb824dc2", "645a43709a8aa035fb824f0a"
  )

allusers <- GADataPart$user_id %>% unique() 
allusers[!(allusers %in% known)]

#also need to remove all events from local host + investigate when it's my device accessing
```


```{r}
#filter out remaining admin activities
GADataPart %<>% dplyr::filter(!str_detect(page_location, "localhost")) #remove events clearly by admin activity
GADataPart %<>% filter(!(GADataPart$device$operating_system_version == "Macintosh Intel 10.15")) 
```


```{r}
#let's clean up a little more

#shorten the url in the page location
GADataPart %<>% mutate(page_location = str_replace(page_location, 'https://myfoodprint.openlab.dev/', '/'))

#reduce our interest even further
GADataPart %<>% select(event_timestamp, ga_session_id, user_id, event_name, page_location,event_bundle_sequence_id, event_nr,  event_category, event_label, engagement_time_msec)
```

```{r categorise events}
event_categories <- read_csv(here("GA","data","classification_event_names.csv"))
GADataPart %<>% left_join(event_categories, by = c("event_name" = "event_name")) %>% 
  mutate(event_category = ifelse(is.na(event_category), "Other", event_category))
GADataPart %<>% relocate(c(event_category, `Event type`, `Special event`), .after = event_name)
```


values that I could be interested in:
- number of receipts added (not in this data)
- time spend with app open
- number of visits
- time spend on help pages
- time spend on pages -- relative
- going through time and views as an indicator of engagement?
- number of clicks on products as indicator of engagement? 
- clicks and scroll as engagement?

note: need to remove visits before briefing (those were me!)


first let's do some analysis on usage time
-> for each session id, identify the min and max time
-> make a new dataframe to caputure session id, start and end time
-> add user_id

```{r}
# GADataPart %>% count(event_name)
# #some of these are passive-events. Let's excluded those
# passiveEvents <- c("page_view","Success","No Receipts Retrieved","No Date Identified on Receipt","Leaving Website","Fetch Receipts","Error Fetching Alternatives","Error")
# #note: page_view would be needed to determine the time spend on a specific page
# GADataPart %<>% filter(!(event_name %in% passiveEvents))
```

```{r}
#test to see if I can easily determine the time between two events in a session

#to do this well we need a separate row/case for each event_bundle_sequence_id. 
#in principle we can ignore all events that are not the first event in a session, as we are interested in the time between events, but we do want to keep information about the different event names. 

GADataPart <- 
  GADataPart %>% 
  group_by(ga_session_id, event_bundle_sequence_id) %>%
  #collapse non-grouping variables
  mutate(across(c(where(is.character) & !page_location), ~paste(unique(.), collapse = ","))) %>% 
  distinct(ga_session_id, event_bundle_sequence_id, .keep_all = T) %>% 
  arrange(ga_session_id, event_timestamp)

#calculate the time delay until the next event
GADataPart %<>% 
  group_by(ga_session_id) %>% 
  mutate(
    action_delay_next = difftime(lead(event_timestamp), event_timestamp, units = "secs"),
    action_delay = difftime(event_timestamp, lag(event_timestamp), units = "secs"),
    .after = "event_timestamp"
  )

#visualize the variation in time between events
hist(GADataPart$action_delay %>% as.numeric())

#some events have a very long time between them. This is because the session is not closed, while there is no action. --> delete single events if they are not joined by other events within a 1-min timespan
GADataPart %<>% 
  add_column(subsession = ifelse(GADataPart$action_delay_next > 60, 1, 0), .after = "ga_session_id") %>%
  mutate(subsession = cumsum(subsession)) 




```

```{r session summary}
GADataPart %<>% 
  mutate(page_location = str_to_lower(page_location))

#calculate session summary
session_summary <-
  GADataPart %>%
  group_by(ga_session_id, subsession, user_id) %>%
  summarise(
    session_start = min(event_timestamp),
    session_end = max(event_timestamp),
    session_time_total = difftime(session_end, session_start, units = "secs"),
    session_time_basket = sum(ifelse(page_location == "/" | (page_location) == "/basket", action_delay_next, 0)),
    session_time_alternatives = sum(ifelse((page_location) == "/alternatives", action_delay_next, 0)),
    session_time_stats = sum(ifelse(page_location == "/stats", action_delay_next, 0)),
    session_time_camera = sum(ifelse(str_detect(page_location, "/camera"), action_delay_next, 0)),
    session_clicks_total = sum(str_detect(`Event type`,"Click")),
    session_clicks_product = sum(str_detect(event_name,"Click Product")),
    session_click_help = sum(str_detect(event_name,"Open Help")),
    session_click_help_detail = sum(str_detect(event_name,"Clicked Detail")),
    session_click_image = sum(str_detect(event_name,"Take Photo")),
    #sum action_delay_next where page_location is not NA

  )

#many sessions are of lenght 0. This is because the session is not closed. We can remove these sessions
session_summary %<>% filter(session_time_total > 1)

#participant summary
participant_summary <- 
  session_summary %>% 
  group_by(user_id) %>% 
  summarise(
    sessions_n = n(),
    time_total = sum(session_time_total),
    time_basket = sum(session_time_basket),
    time_alternatives = sum(session_time_alternatives),
    time_camera = sum(session_time_camera),
    time_stats = sum(session_time_stats),
    clicks_total = sum(session_clicks_total),
    clicks_product = sum(session_clicks_product),
    clicks_help = sum(session_click_help),
    clicks_help_detail = sum(session_click_help_detail),
    clicks_image = sum(session_click_image),
  )

#total summary
total_summary <- 
  session_summary %>% 
  ungroup() %>%
  summarise(
    sessions_n = n(),
    time_total = sum(session_time_total),
    time_basket = sum(session_time_basket),
    time_alternatives = sum(session_time_alternatives),
    time_camera = sum(session_time_camera),
    time_stats = sum(session_time_stats),
    clicks_total = sum(session_clicks_total),
    clicks_product = sum(session_clicks_product),
    clicks_help = sum(session_click_help),
    clicks_help_detail = sum(session_click_help_detail),
    clicks_image = sum(session_click_image),
  )

```

```{r create tables participants}
participant_summary_desc <- 
participant_summary %>%
  #convert time variables to minutes and numeric
  mutate(across(contains("time"), ~ as.numeric(.)/60)) %>%
  rename_with(~paste0(., "_min"), contains("time")) %>%
  # mutate(across(where(is.numeric), ~round(.,2))) %>%          
  pivot_longer(
    cols = everything() & !user_id,
    names_to = "variable",
    values_to = "value",
    cols_vary = "slowest"
  )

#turn the variable into a factor to maintain the order when summarising (below)
participant_summary_desc %<>%
  mutate(variable = factor(variable, levels = unique(participant_summary_desc$variable)))

#calculate participant mean, median, sd, and IQR
participant_summary_desc %<>%
  #first calculate the statistics 
  group_by(variable) %>%
  select(-user_id) %>%
  summarise(
    across(
      everything(),
        .fns = list(
          min = min,
          p0.25 = ~quantile(., 0.25),
          median = median, 
          p0.75 = ~quantile(., 0.75),
          max = max,
          distribution = ~ list(.x) #we will create the distribution graph in a next step
        ),
        .names = "{.fn}"
    ),
  ) 

#separate the variable to create a grouping variable to be used for the GT table
participant_summary_desc %<>%
  separate_wider_delim(variable, names = c("group","var"), delim = "_", too_many = "merge")


library(gtExtras)

participant_summary_desc_GT <-
participant_summary_desc %>%
  #restyle the variable names
  mutate(var = str_replace_all(var, "_", " ") %>% str_replace_all(., "min", "[min:sec]") %>% str_replace_all(., "image", "Take picture") %>%  str_to_sentence()) %>%
  mutate(group = str_replace_all(group, "time", "Time spent") %>% str_replace_all(., "clicks", "Clicks")) %>%
  group_by(group) %>%
  gt(rowname_col = "var") %>%
  gt::fmt_number(columns = min:max, decimals = 0) %>%
  # gt::fmt_number(columns = median:max, rows = contains("min"), decimals = 2) %>%
  fmt_duration(
    columns = min:max,
    rows = contains("min"), 
    input_units = "minutes",
    output_units = c("minutes", "seconds"),
    duration_style = "colon-sep"
  ) %>%
  #creating the distribution graph
  gt_plt_dist(contains("distribution"), type = "boxplot", same_limit = F) %>%
  #rename column names
  gt::cols_label(min = "Q0", p0.25 = "Q1", median = "Q2", p0.75 = "Q3", max = "Q4") %>%
  #apply styling
  tab_style(
    style = cell_text(weight = "bold"),
    locations = list(cells_column_labels(everything()),cells_row_groups(everything()))
  ) %>%
  tab_options(data_row.padding = px(3)) %>%
  #add a footnote explaining the stats displayed
  tab_footnote(footnote = md("Q0 = min"), locations = cells_column_labels(min)) %>%
  tab_footnote(footnote = md("Q1 = 25th percentile"), locations = cells_column_labels(p0.25)) %>%
  tab_footnote(footnote = md("Q2 = median"), locations = cells_column_labels(median)) %>%
  tab_footnote(footnote = md("Q3 = 75th percentile"), locations = cells_column_labels(p0.75)) %>%
  tab_footnote(footnote = md("Q4 = max"), locations = cells_column_labels(max))

participant_summary_desc_GT
  
#save the table
gtsave(participant_summary_desc_GT, file = here("output","tables","GA_participant_summary.png"))
gtsave(participant_summary_desc_GT, file = here("output","tables","GA_participant_summary.docx"))
  
```

```{r create tables total}
  
```


```{r create table sessions}
#first a small adjustment to lable names, such that we get nice grouping later
names(session_summary) <- names(session_summary) %>% str_replace_all("_click_", "_clicks_") 

session_summary_desc <- 
  session_summary %>% 
  ungroup() %>%
  #drop columns we don't need
  select(-c(ga_session_id:session_end)) %>%
  #convert time variables to minutes and numeric
  mutate(across(contains("time"), ~ as.numeric(.)/60)) %>%
  rename_with(~paste0(., "_min"), contains("time")) %>%
  pivot_longer(
    cols = everything(),
    names_to = "variable",
    values_to = "value",
    cols_vary = "slowest"
  )

#turn the variable into a factor to maintain the order when summarising (below)
session_summary_desc %<>%
  mutate(variable = factor(variable, levels = unique(session_summary_desc$variable)))

#calculate participant mean, median, sd, and IQR
session_summary_desc %<>%
  #first calculate the statistics 
  group_by(variable) %>%
  summarise(
    across(
      everything(),
        .fns = list(
          min = min,
          p0.25 = ~quantile(., 0.25),
          median = median, 
          p0.75 = ~quantile(., 0.75),
          max = max,
          distribution = ~ list(.x) #we will create the distribution graph in a next step
        ),
        .names = "{.fn}"
    ),
  ) 

#separate the variable to create a grouping variable to be used for the GT table
session_summary_desc %<>%
  mutate(variable = str_remove(variable, "session_")) %>%
  separate_wider_delim(variable, names = c("group","var"), delim = "_", too_many = "merge")

#make the table
session_summary_desc_GT <-
session_summary_desc %>%
  #restyle the variable names
  mutate(var = str_replace_all(var, "_", " ") %>% str_replace_all(., "min", "[min:sec]") %>% str_replace_all(., "image", "Take picture") %>%  str_to_sentence()) %>%
  mutate(group = str_replace_all(group, "time", "Time spent") %>% str_replace_all(., "clicks", "Clicks")) %>%
  group_by(group) %>%
  gt(rowname_col = "var") %>%
  gt::fmt_number(columns = min:max, decimals = 0) %>%
  # gt::fmt_number(columns = median:max, rows = contains("min"), decimals = 2) %>%
  fmt_duration(
    columns = min:max,
    rows = contains("min"), 
    input_units = "minutes",
    output_units = c("minutes", "seconds"),
    duration_style = "colon-sep"
  ) %>%
  #creating the distribution graph
  gt_plt_dist(contains("distribution"), type = "boxplot", same_limit = F) %>%
  #rename column names
  gt::cols_label(min = "Q0", p0.25 = "Q1", median = "Q2", p0.75 = "Q3", max = "Q4") %>%
  #apply styling
  tab_style(
    style = cell_text(weight = "bold"),
    locations = list(cells_column_labels(everything()),cells_row_groups(everything()))
  ) %>% 
  tab_options(data_row.padding = px(3)) %>%
  #add a footnote explaining the stats displayed
  tab_footnote(footnote = md("Q0 = min"), locations = cells_column_labels(min)) %>%
  tab_footnote(footnote = md("Q1 = 25th percentile"), locations = cells_column_labels(p0.25)) %>%
  tab_footnote(footnote = md("Q2 = median"), locations = cells_column_labels(median)) %>%
  tab_footnote(footnote = md("Q3 = 75th percentile"), locations = cells_column_labels(p0.75)) %>%
  tab_footnote(footnote = md("Q4 = max"), locations = cells_column_labels(max))

session_summary_desc_GT

#save the table
gtsave(session_summary_desc_GT, file = here("output","tables","GA_session_summary.png"))
gtsave(session_summary_desc_GT, file = here("output","tables","GA_session_summary.docx"))
  
```


```{r combined summary table}

#row bind the two tables (p0.25, median, p0.75 only)
combined_summary <- 
  bind_rows(
    list(
      by_participant = participant_summary_desc %>% select(-distribution), 
      by_session = session_summary_desc %>% select(-distribution)
    ),
    .id = "id"
  )

#for this situation we actually want duration values in seconds, such that we can round values
combined_summary <- 
  combined_summary %>%
  #time values in seconds
  mutate(across(min:max, ~if_else(str_detect(group, "time"), as.numeric(.)*60, .))) %>%
  #rename the variables to indicate that they are in seconds
  mutate(var = str_replace_all(var, "_min", "")) %>%
  #round the values
  mutate(across(min:max, ~ round(.,0))) %>%
  #convert values to character, so that we can have time and numeric formatting in the same column
  mutate(across(min:max, 
                ~ ifelse(group == "time",
                         #format time in mm:ss
                         sprintf("%02d:%02d", . %/% 60, . %% 60),
                         #format numeric values
                         as.character(.)
                )
  ))

#create the descriptive values that we want to display
combined_summary %<>%
  group_by(group,var, id) %>%
  mutate(desc = paste0(median, " [", p0.25, ", ", p0.75, "]"),.keep = "none")

#format the total summary to be added to the combined summary
overall_summary <- 
  total_summary %>%
  # mutate(across(contains("time"), ~ as.numeric(.))) %>%
  # rename_with(~paste0(., "_min"), contains("time")) %>%
  mutate(across(everything(), ~ round(as.numeric(.),0))) %>%
  pivot_longer(
    cols = everything(),
    names_to = "variable",
    values_to = "value",
    cols_vary = "slowest"
  ) %>% 
  separate_wider_delim(variable, names = c("group","var"), delim = "_", too_many = "merge") %>%
  mutate(desc = 
             ifelse(group == "time",
             #format time in hh:mm
             sprintf("%02d:%02d:%02d", value %/% 3600, value %% 3600 %/% 60, value %% 60 %/% 1),
             #format numeric values
             as.character(value)
  )) %>% 
  select(-value)

#bind
combined_summary <- 
  bind_rows(
    combined_summary,
    overall_summary %>% add_column(id = "overall")
  )

#pivot
combined_summary %<>%
  pivot_wider(names_from = id, values_from = desc) %>%
  select(group, var, overall, by_participant, by_session)

#display as GT table
combined_summary_GT <-
combined_summary %>%
  #restyle the variable names
  mutate(var = str_replace_all(var, "_", " ") %>% str_replace_all(., "image", "Take picture") %>%  str_to_sentence()) %>%
  mutate(group = str_replace_all(group, "time", "Time spent  [hh:mm:ss] or [mm:ss]") %>% str_to_sentence(.)) %>%
  group_by(group) %>%
  gt(rowname_col = "var") %>%
  #rename column names
  gt::cols_label(overall = "Overall", by_participant = "By participant", by_session = "By session") %>%
  #apply styling
  tab_style(
    style = cell_text(weight = "bold"),
    locations = list(cells_column_labels(everything()),cells_row_groups(everything()))
  ) %>% 
  tab_options(data_row.padding = px(3)) %>%
  #add a footnote explaining the stats displayed
  tab_footnote(footnote = md("median [Q1, Q3]"), locations = cells_column_labels(contains("by_")))

combined_summary_GT

#save the table
gtsave(combined_summary_GT, file = here("output","tables","GA_summary.png"))
gtsave(combined_summary_GT, file = here("output","tables","GA_summary.docx"))


```

```{r}
```











